{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"# Introduction\nThis notebook was created to learn basic techniques of data manipulation and machine learning. The idea is to use the dataset UCI_Credit_Card to improve basic skills of data cleaning, data analysis, data visualization and machine learning. It is primarily intended to help myself understanding what to do and how. Any feedback is welcome.\n\n## Variables\nThere are 25 variables:\n\n* ID: ID of each client\n* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n* SEX: Gender (1=male, 2=female)\n* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n* AGE: Age in years\n* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n* PAY_2: Repayment status in August, 2005 (scale same as above)\n* PAY_3: Repayment status in July, 2005 (scale same as above)\n* PAY_4: Repayment status in June, 2005 (scale same as above)\n* PAY_5: Repayment status in May, 2005 (scale same as above)\n* PAY_6: Repayment status in April, 2005 (scale same as above)\n* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n* default.payment.next.month: Default payment (1=yes, 0=no)\n","metadata":{"_uuid":"a74f371efbfb4ad4087242386c893e69c72d720d","_cell_guid":"41ecf8cf-6358-4bfd-88b7-a721976fccfc"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Import basic libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# import visualization libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"5ba24adc75c0d29f38ff44a0718bb2d8034ba584","collapsed":true,"_cell_guid":"2bbbd9be-d5d6-4607-9786-072d67b87303"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Load the data\n\ndf = pd.read_csv('../input/UCI_Credit_Card.csv')\ndf.sample(3)","metadata":{"_uuid":"866eacd59f720b77731a2e041471b5999ac4906c","_cell_guid":"373de127-2f57-439e-b3fb-febc86cf821c"}},{"cell_type":"markdown","source":"As a first step, let's have a look if there are missing or anomalous data","metadata":{"_uuid":"391f4b0edb2c804475fd6e35cd738025095f00b5","_cell_guid":"c855e309-85e8-426f-ab80-050b16db868c"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df.info()","metadata":{"_uuid":"bf10536e7bcca34164565abf554bffe558ed0d5f","_cell_guid":"f6bc9ca2-b40e-4346-838a-922e110d5f20"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Categorical variables description\ndf[['SEX', 'EDUCATION', 'MARRIAGE']].describe()","metadata":{"_uuid":"7ff6b6f89760fafc327b3852e03333fb547ff784","_cell_guid":"f1796586-38ba-4b68-990e-33323cbc2856"}},{"cell_type":"markdown","source":"No missing data, but a few anomalous things:\n* EDUCATION has cathegory 5 and 6 that are unlabeled, moreover it has a label 0 that is undocumented.\n* MARRIAGE has a label 0 that is undocumented","metadata":{"_uuid":"53976f540202b3d7d62074e0fb9b5e3803664a55","_cell_guid":"0f1e309a-146d-4784-86cd-75bfe13e60e9"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Payment delay description\ndf[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].describe()","metadata":{"_uuid":"1a40fe4404d10cc9f0073c2fb2b87f4b9f40d4ac","_cell_guid":"39110051-7da4-4e26-900e-2eea1e8efd28"}},{"cell_type":"markdown","source":"They all present an undocumented label -2. If 1,2,3, etc are the months of delay, 0 should be labeled 'pay duly' and every negative value should be seen as a 0. But we will get to that later","metadata":{"_uuid":"e612682a3c7ca90d276a518d009b39b3d75fb5da","_cell_guid":"b77758bb-773d-4908-9dc0-421d35127259"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Bill Statement description description\ndf[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']].describe()","metadata":{"_uuid":"8960233ca3309cd4ff06610b8f8132a7e10d5abb","_cell_guid":"bcdaba60-c776-491b-92e5-80d5fdca8b30"}},{"cell_type":"markdown","source":"Negative values can be interpreted as credit? Has to be investigated","metadata":{"_uuid":"ac8957e78333c9288d64c97cbff72ad08ab77f31","_cell_guid":"465b66a4-0da7-49a9-939a-67f3e7dc37c8"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"#Previous Payment Description description description\ndf[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']].describe()","metadata":{"_uuid":"110119ecd8d7d36b1d835a2e821a91dd7fd9527c","_cell_guid":"8d96485a-4215-47bf-9d0f-247aebddf408"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df.LIMIT_BAL.describe()","metadata":{"_uuid":"0fb66c7c87b1b63dd7018ab642f7faef11ef70ed","_cell_guid":"56705789-b5a9-4a63-8ef1-26687270609e"}},{"cell_type":"markdown","source":"The range is very broad, Investigation required.\n\nTwo columns bother me because are poorly labeled.","metadata":{"_uuid":"8695b9a4741e2d35bf59f238154a072e6f585192","_cell_guid":"745c76aa-1d96-4588-84b3-4718168d54c0"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df = df.rename(columns={'default.payment.next.month': 'def_pay', \n                        'PAY_0': 'PAY_1'})\ndf.head()","metadata":{"_uuid":"7a0dfd1323e523a69799ec877fc1107fb38ce019","_cell_guid":"5e7e7299-3a20-4266-a2df-036123ed86e4"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# I am interested in having a general idea of the default probability\ndf.def_pay.sum() / len(df.def_pay)","metadata":{"_uuid":"8df4001b8ccd4dfd2d4213db898e7d07070c0ce7","_cell_guid":"0cb4683d-aba0-44a9-8a46-db37c5b42c88"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Other ways of getting this kind of numbers (as a reference for newbies like myself)\nprint(df.shape)\nprint(df.shape[0])\nprint(df.def_pay.count())\nprint(len(df.axes[1]))","metadata":{"_uuid":"a4d87d8e1a1deb2400eac839db29f6b1bbcc5cda","_cell_guid":"1a08707b-0b25-4946-9e56-fa842722137f"}},{"cell_type":"markdown","source":"# Categorical variables\n## Cleaning\nThere is not much to clean, but it is a good occasion to learn how to look at a column and replace anomalous entries\n\n### Looking at our columns with more attention","metadata":{"_uuid":"c48a743fbab7a7ab9e3785a540e1c053c56dfff5","_cell_guid":"d1cc345f-2b25-4a70-b90d-c1be24b674c5"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df.SEX.value_counts() #this is fine, more women than men","metadata":{"_uuid":"15519471129821eec1c36f9ea785b3ce021cd615","_cell_guid":"8767195d-c9eb-4e6e-a2b3-ac0856c27d0e"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df['MARRIAGE'].value_counts()","metadata":{"_uuid":"7aea6cb700c904fc7aee787476868bb1a69037fe","_cell_guid":"cedffa25-ac05-4d29-9f8c-a35cdbe04051"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df.EDUCATION.value_counts() # yes, I am using different ways of calling a column","metadata":{"_uuid":"58a431301f0ba1adbf4d5de7406acb310c0592a6","_cell_guid":"f8b4fc4e-c5b2-46c3-8a98-19d8b317758c"}},{"cell_type":"markdown","source":"### Fixing the mislabeled entries\n\nThe 0 in MARRIAGE can be safely categorized as 'Other' (thus 3). \n\nThe 0 (undocumented), 5 and 6 (label unknown) in EDUCATION can also be put in a 'Other' cathegory (thus 4)\n\nThus is a good occasion to learn how to use the .loc function","metadata":{"_uuid":"aa5abf379db06d704329294b89f06de63d29f796","_cell_guid":"fc9bf7b7-3ab3-49c8-93ed-fad5b0cb46c7"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"fil = (df.EDUCATION == 5) | (df.EDUCATION == 6) | (df.EDUCATION == 0)\ndf.loc[fil, 'EDUCATION'] = 4\ndf.EDUCATION.value_counts()","metadata":{"_uuid":"6fa98986fddfe91584cca5db8c1d3ba8a35d9afb","_cell_guid":"fe9b185b-3275-4d69-a853-93762bf4e5a4"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df.loc[df.MARRIAGE == 0, 'MARRIAGE'] = 3\ndf.MARRIAGE.value_counts()","metadata":{"_uuid":"c0ef5c3f3046d7dbe44549f7e58bd06e698f48d2","_cell_guid":"09a4adf4-6bb2-4728-ad64-c3e49439897c"}},{"cell_type":"markdown","source":"One might wonder what these labels might mean something.\n\n\"Other\" in education can be an education lower than the high school level\n\n\"Other\" in marriage could be, for example, \"divorced\". \n\n\n\nNumerically they are not very relevant. We can decide later if we can drop them (or, even better, if dropping them can improve our result)\n\n## Analysis\n\nWe can look at how these three variables are correlated to our target 'def_pay'. The goal is to see if they can be relevant to our models or not and, most importantly, it gives us a chance of learning a few basic techniques.\n\n### The magic use of groupby\n\nIt is a very easy tool to directly see the relation between one category and the other. Just for pedagocial purposes, we can do it step by step.\n\nLet's start by looking at the correlation between gender and default\n","metadata":{"_uuid":"0c49a99c3a2c7d850b624ee5d37f40f3a9d7af1e","_cell_guid":"a0fedc10-50d9-4810-b6db-68b33ba9d090"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df.groupby(['SEX', 'def_pay']).size()","metadata":{"_uuid":"e9281fdc52d798fc50219da3e67951b803a6531d","_cell_guid":"69b7024f-150f-4741-a633-ac50299560ad"}},{"cell_type":"markdown","source":"Well, this doesn't look very good, why don't we create a dataframe out of it?","metadata":{"_uuid":"07a2877a13754746288c80ed01d4dcf146465f5d","_cell_guid":"e180f386-d0d5-4f19-ab3e-45056926d86a"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"gender = df.groupby(['SEX', 'def_pay']).size().unstack(1)\n# 1 is the default for unstack, but I put it to show explicitly what we are unstacking\ngender","metadata":{"_uuid":"4661b62a4fea453713aaeed344328339368d4a7d","_cell_guid":"380188fb-149b-4171-aefa-3195c7c24524"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Another, easier, way is to just use crosstab\npd.crosstab(df.SEX, df.def_pay)","metadata":{"_uuid":"97f16486f40a159c280fd4249fa816de23319349","_cell_guid":"3459adfd-9fbf-4ea8-8f36-de5f55478613"}},{"cell_type":"markdown","source":"We can do two things: plot directly or compute the probability for each gender to default according to our dataset","metadata":{"_uuid":"e3c5c90654174b90bfd5c0bdaf6d68c3851a5759","_cell_guid":"f4d14f6e-d879-4a8b-8820-150894b0b6e7"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"gender.plot(kind='bar', stacked = True)","metadata":{"_uuid":"b54469fe0d031522ebdb19f8c2d7679cb58b54ce","_cell_guid":"21f41873-cfea-473d-8cf9-e8ca8a8728cf"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"gender['perc'] = (gender[1]/(gender[0] + gender[1])) \n#this creates a new column in our dataset\ngender","metadata":{"_uuid":"db5d20ab4498a0af5ea7dfff5404865e20785e14","_cell_guid":"12b9c39c-ad04-4179-8030-6817ae7de84c"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# and we can visualize it\ngender.perc.plot(kind = 'bar')","metadata":{"_uuid":"f6153b94d0714e87c66d4e279802d91bc868b094","_cell_guid":"0dd7e986-54a0-4b29-baa3-405018616828"}},{"cell_type":"markdown","source":"Considering that about 22% of the customers will default, we see a couple of things:\n* there are significantly more women than men\n* men are most likely going to default the next month\n\nHowever, we don't have to jump to any conclusion just yet since there might be some lurking variable that justifies the data better (and, being SEX the first variable we look at, it is most likely the case). However, nice result and move on.\n\nNow let's look at EDUCATION","metadata":{"_uuid":"86257389e1add3d0e9a96455bc198d48d5b9b48a","_cell_guid":"2da419cf-9c4a-4219-a2d6-519a915f4d43"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"ed = df.groupby(['EDUCATION', 'def_pay']).size().unstack()\ned.plot(kind = 'bar', stacked = True)","metadata":{"_uuid":"32d9c38ff059e12bc279dc2aea625340b5529b8b","_cell_guid":"0a68c52c-9cdd-41dd-abf4-dbd7345d0d9a"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"ed['perc'] = (ed[1]/(ed[0] + ed[1]))\ned","metadata":{"_uuid":"c8fd41d79b3ef0ae1682fce37b00c7cac0ad8851","_cell_guid":"41d01848-aafe-477a-a394-82f9cc1c7881"}},{"cell_type":"markdown","source":"It seems that the higher is the education, the lower is the probability of defaulting the next month. Only exception is for the category labeled \"Other\" that, if we stick to the documentation, would be lower than high school. However, numerically they will not have much weight in the final result.\n\nAt last, let's look at MARRIAGE.","metadata":{"_uuid":"7637df36644eece2d63355f6d07033d9c0f0a892","_cell_guid":"40ca0a46-f3ee-47f0-894c-dc09e3e2a694"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"mar = df.groupby(['MARRIAGE', 'def_pay']).size().unstack()\nmar.plot(kind = 'bar', stacked = True)","metadata":{"_uuid":"893d2083142b96843e9b2ab8257a4371942180a8","_cell_guid":"d82c232e-b453-4c4e-8ffa-0d94db8f3955"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"mar['perc'] = (mar[1]/(mar[0] + mar[1]))\nmar","metadata":{"_uuid":"99b6f7adf15144188dc8d44fb7545870c2103389","_cell_guid":"01794fcf-20b3-4a7a-b09e-f3029b6aa252"}},{"cell_type":"markdown","source":"Here it seems that married people are most likely to default as well as the misterious category \"Other\" ( which is again numerically less relevant than the others)\n\nAll considered, these three categories seem to affect the result we want to predict. Thus we keep them in mind for later. \n\nI try to explain these first results and, while I can imagine how marital status or education can determine the balance of your credit card, I can't find a way of explaining why the type of genitals can do that as well. This particular result could probably get more meaning when put in the context of the society this people belong to.\n\nRevealing gender inequalities in not our priority (at least not on a beginner notebook on Kaggle), so we move on.\n\nOne consideration: we did the same thing over and over, good for practice but still incomplete. Let's see a slightly different way of obtaining the same percentages.","metadata":{"_uuid":"f84dc4d5fedbc276bc39f346ae49d4ad9fc61e08","_cell_guid":"20168d4c-f458-4bb8-b626-6d48e77ba996"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df[[\"SEX\", \"def_pay\"]].groupby(['SEX'], \n                                        as_index=False).mean().sort_values(by='def_pay', \n                                                                           ascending=False)","metadata":{"_uuid":"8564e39c6fb7ced6820d4477f07ee2c7fba5e64d","_cell_guid":"50fd566a-8633-4b52-bab4-ab29628e42b4"}},{"cell_type":"markdown","source":"A newbie as myself likes to mess around with options. We remove the as_index (which will just make the first column the index) and the ascending (which will make them ascending)","metadata":{"_uuid":"b8230404161b494ad6152383b2c240c731460e2f","collapsed":true,"_cell_guid":"abf05017-6a01-4b22-acea-d6c7f6dbad8b"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df[[\"SEX\", \"def_pay\"]].groupby(['SEX']).mean().sort_values(by='def_pay')","metadata":{"_uuid":"58a774c394575e3a32badadad240130d922456a8","_cell_guid":"e07b61f3-e706-4423-85c2-1f8c8057d660"}},{"cell_type":"markdown","source":"One last thing before moving on. If you have to perform repetitive actions like this one, you want to write a function to do it for you. It is a good exercise and it will reveal what we put under the carpet when we called the columns with df[0] and df[1]","metadata":{"_uuid":"48fad6a66052a8cc9296e27537592ffc2d856996","_cell_guid":"e54e8536-acd9-46d1-b8ad-54a337680e00"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def corr_2_cols(Col1, Col2):\n    res = df.groupby([Col1, Col2]).size().unstack()\n    res['perc'] = (res[1]/(res[0] + res[1]))\n    return res\n\ncorr_2_cols('SEX', 'def_pay')","metadata":{"_uuid":"cf8701f682b0d9e6224920ba14f7d095297c1d9a","_cell_guid":"18f41653-99c0-4609-bae5-a8baebe1c805"}},{"cell_type":"markdown","source":"Looks great, it does everything we did before, life is wonderful and we can all quit recreational drugs to feel alive again because we don't need them any longer.\n\nNot really.\n\nIf we simply try to do corr_2_cols('MARRIAGE', 'SEX') we get an index error. This is because with res[1] we are actually calling the column called 1 in res, which just happens to be also in position 1. Let's write it in a more correct way","metadata":{"_uuid":"531bf040ec36c0bc23b16750df8007c067fd9173","_cell_guid":"157a0369-b322-46de-a346-e7cff6263da8"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def corr_2_cols(Col1, Col2):\n    res = df.groupby([Col1, Col2]).size().unstack()\n    res['perc'] = (res[res.columns[1]]/(res[res.columns[0]] + res[res.columns[1]]))\n    return res\n\ncorr_2_cols('SEX', 'def_pay')","metadata":{"_uuid":"e9ab8621a1c3604933e54527c8f2df79478cbacc","_cell_guid":"22c8ca40-8cbd-46e3-ab5e-86d938fef9ec"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"corr_2_cols('MARRIAGE', 'SEX')","metadata":{"_uuid":"9abe1a0f9ad9d8e5e02aa5ba98b75a6b5c429c31","_cell_guid":"d7c28199-31aa-411b-838e-3e308ee102a3"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"corr_2_cols('EDUCATION', 'SEX')","metadata":{"_uuid":"004dcf7c8c91c0a1a57ad658c0489498ee0cc48f","_cell_guid":"978f27fe-ade2-46bc-bf51-57ec2c689e86"}},{"cell_type":"markdown","source":"Now we are happier, we have written a function that would have saved us some time and we can see some other correlations. For example, in our dataset the percentage of women with higher education is comparable with the one with lower education, which is not a common result in many countries.\n\nHowever, our function works only if the unstacked column has only 2 possible values. Can you write a more general one?\n\n","metadata":{"_uuid":"d9aee7ce4995f322db896ca938d555b0a7e9115a","_cell_guid":"d55f3fe5-2576-47e2-99f5-747f133fd41e"}},{"cell_type":"markdown","source":"# Dealing with age\n\nWe use some seaborn functions, I found most of them in kernels of the Titanic competition but, again, the all purpose is to practice so.. here we go","metadata":{"_uuid":"af2faafe98982c2bc07cc53348758688376c3888","_cell_guid":"517639b1-b0fb-455a-8101-d25f4320062b"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# import the libraries we need\n#import seaborn as sns\n#import matplotlib.pyplot as plt\n#%matplotlib inline \n# Already done in the first cell, but kept here as reference","metadata":{"_uuid":"f0c1a22550c1a4dc26242f40c39415ce16eef787","collapsed":true,"_cell_guid":"8e3dcc5c-a3fe-496c-8f53-3e2dc3dbd28d"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"g = sns.FacetGrid(df, col = 'def_pay')\ng.map(plt.hist, 'AGE')","metadata":{"_uuid":"30c242012ca609466dec94b6d2eccfa25a20d294","_cell_guid":"ac0fe3ea-a5af-4a9e-9568-8f4324941d6f"}},{"cell_type":"markdown","source":"Or we can even divide them further and visualize 4 distributions","metadata":{"_uuid":"73300aa861098ef6bfceb7e5375c2cab5882d90e","_cell_guid":"982eb498-3d83-4eca-af9d-e03940090a90"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"g = sns.FacetGrid(df, col = 'def_pay', row = 'SEX')\ng.map(plt.hist, 'AGE')","metadata":{"_uuid":"b21adecb70b7a34e5f2821a7872f1392b07082bf","_cell_guid":"3c60d00b-8415-48be-b077-37edf4187474"}},{"cell_type":"markdown","source":"It is fair to say that this doesn't really help, so let's use the hue option","metadata":{"_uuid":"e88144f2c97e0a976d632d7470a20265dfd6dbd0","_cell_guid":"ed126993-fa8b-4250-973e-67ac07c9fafb"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"g = sns.FacetGrid(df, col='SEX', hue='def_pay')\ng.map(plt.hist, 'AGE', alpha=0.6, bins=25) #alpha is for transparency\ng.add_legend()","metadata":{"_uuid":"99dafced0f92000c8a6afb4cd99ee15fab400013","_cell_guid":"e11f7bd5-a073-4359-9e5e-8cd000138a33"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"g = sns.FacetGrid(df, col='def_pay', row= \"MARRIAGE\", hue='SEX')\ng.map(plt.hist, 'AGE', alpha=0.3, bins=25) \ng.add_legend()","metadata":{"_uuid":"b6a60c7bfae5acded5a06da8f8a1569405e1b34d","_cell_guid":"00c7b58b-6bda-4b25-b3c2-589b65527d61"}},{"cell_type":"markdown","source":"Can be useful to create categories out of our age distribution. We can do it in three ways (that I know of).\n\nFirst, we could simply create a column and put a bunch of filters to fill it with the help of loc","metadata":{"_uuid":"2cde6276800d13314e21a2d051e88d15a4e0f8cb","_cell_guid":"9101f13f-1d6d-4149-94b3-95c650a2192b"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df['AgeBin'] = 0 #creates a column of 0\ndf.loc[((df['AGE'] > 20) & (df['AGE'] < 30)) , 'AgeBin'] = 1\ndf.loc[((df['AGE'] >= 30) & (df['AGE'] < 40)) , 'AgeBin'] = 2\ndf.loc[((df['AGE'] >= 40) & (df['AGE'] < 50)) , 'AgeBin'] = 3\ndf.loc[((df['AGE'] >= 50) & (df['AGE'] < 60)) , 'AgeBin'] = 4\ndf.loc[((df['AGE'] >= 60) & (df['AGE'] < 70)) , 'AgeBin'] = 5\ndf.loc[((df['AGE'] >= 70) & (df['AGE'] < 81)) , 'AgeBin'] = 6\ndf.AgeBin.hist()","metadata":{"_uuid":"9be302f5356a9355a69a260b3c3547f217fe2fd8","_cell_guid":"4fdcb784-fcaf-4a24-9026-1a19e024f014"}},{"cell_type":"markdown","source":"This works gives you control of how big the bins are BUT, let's face it, now that we know how loc works (sort of) it is not practical. We can use the second method that I know, which is to cut","metadata":{"_uuid":"e1a9e57507187b82b690f2378e000f69f43c92dc","_cell_guid":"55069421-5283-47b1-aee9-831550fede3b"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"bins = [20, 29, 39, 49, 59, 69, 81]\nbins_names = [1, 2, 3, 4, 5, 6]\ndf['AgeBin2'] = pd.cut(df['AGE'], bins, labels=bins_names)\ndf.AgeBin2.hist()","metadata":{"_uuid":"cccb2d9ef63361b9cb07bb916270beea70815126","_cell_guid":"fd1f3c04-b7d4-459c-b316-99c93c662873"}},{"cell_type":"markdown","source":"We notice 2 things:\n* the bins have to be defined in a slightly counter intuitive way (at first) due to the fact that it includes the upper limit (as you can check by just changing the bins. You can play with the option \"right\" that is True by default\n* the bins names have to be less numerous than the bins, i.e. with one bin you do bins = [20,81] and bins_names = [ 1 ] \n\nThere is actually a faster way of doing 6 bins with cut, at the price of losing control on how big these bins are","metadata":{"_uuid":"8f8ad88d9a4473235c1a087e7d29cc9f4fd4c9e4","_cell_guid":"1e4b234d-b6a6-42f7-bcd2-fd169457cbd1"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df['AgeBin3'] = pd.cut(df['AGE'], 6)\ndf.AgeBin3.value_counts()","metadata":{"_uuid":"df75930554ee4e8cc74872bca525dccfe75896fc","_cell_guid":"2932763f-16de-4d3f-93a5-68a1a8a289c4"}},{"cell_type":"markdown","source":"This is slightly different than we did so far, but also faster. To have the right names we need to add an option to the cut command","metadata":{"_uuid":"b4f8d06388c259af5662ccba1bf46ba867e12e94","_cell_guid":"19a47214-904e-47b6-ab1e-531d86e97798"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df['AgeBin3'] = pd.cut(df['AGE'], 6, labels=bins_names)\ndf.AgeBin3.hist()","metadata":{"_uuid":"3056d18de6782a19579fa17bd7ca29454abe208c","_cell_guid":"d7b9047a-47b8-45cb-86ae-ba0c345c3989"}},{"cell_type":"markdown","source":"Another way of cutting a countinuos variable can be with a quantile-based discretization. This is done by the function qcut","metadata":{"_uuid":"4c5108be1fabe361c1d8dd14601d2fe429245f73","_cell_guid":"8e984672-2be8-4a66-9bc2-12aa29064677"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df['AgeBin4'] = pd.qcut(df['AGE'], 6)\ndf.AgeBin4.value_counts()","metadata":{"_uuid":"8822f28268ec073a3211d4296171cbd7d79716a1","_cell_guid":"7cda57eb-8a5b-4979-9738-d9c7d4fb5afe"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df['AgeBin4'] = pd.qcut(df['AGE'], 6, labels=bins_names)\ndf.AgeBin4.hist()","metadata":{"_uuid":"8df79836c437f7749d08fe68fb8e3e67c0c15e97","_cell_guid":"f7fcf1eb-e9f9-4647-951a-848d29be2866"}},{"cell_type":"markdown","source":"This can be useful if, for example, you have outliers (like in the balance variable it is possible there will be some) because those outliers would just fall into the extremal categories.\n\nI still like my age feature, but we don't need so many bin categories. We keep the fast one only","metadata":{"_uuid":"b4ab6e491484ae261af150c5294fb7d7e821f4d7","_cell_guid":"e26a2dce-2d00-42bb-910b-d94d13495aa9"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"del df['AgeBin2']\ndel df['AgeBin3']\ndel df['AgeBin4'] # we don't need these any more\ndf['AgeBin'] = pd.cut(df['AGE'], 6, labels = [1,2,3,4,5,6])\n#because 1 2 3 ecc are \"categories\" so far and we need numbers\ndf['AgeBin'] = pd.to_numeric(df['AgeBin']) \ndf.AgeBin.hist()","metadata":{"_uuid":"30f5a653e5fb7e288fcd07551e88b958ef4e1f2f","_cell_guid":"897aaa54-ea7b-4864-9745-cbe2f6242a5b"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"corr_2_cols('AgeBin', 'def_pay')","metadata":{"_uuid":"b73aedc6f1a71bd619683856e9b185edb75ffffa","_cell_guid":"396b8911-b441-4505-bb8d-81ef9f19e8f9"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"corr_2_cols('AgeBin', 'SEX')","metadata":{"_uuid":"0b7c8722c4c3eb9409ccb0e60f00af9cab353b63","_cell_guid":"2e907188-546b-4340-97be-eec6d113856a"}},{"cell_type":"markdown","source":"I am keeping both the AGE and the AgeBin features because I am curious on what difference does it make for our models.\n\n## Time to understand the rest\n\nThe variables regarding the credit and payment delays were not explored at all and I am not confortable with using them in a model if I am not sure of their meaning. An important thing I have to remember is that I will make some assumptions and I have to verify them.\n\nFirst, looking at the number of months of delay, we see that the 'pay duly' should be labeled as -1. So I need to know what 0 and -2 mean. I suspect they can all be called 0, but let's see, for example, their BILL_AMT","metadata":{"_uuid":"8fa819d4487463239c0c75b7eb2087c5c369986b","_cell_guid":"5ba73a20-fe40-4614-9c99-96df0e4143fa"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df[df.PAY_1 < 1][['BILL_AMT2', 'PAY_AMT1', 'BILL_AMT1', 'PAY_1']].sample(20)","metadata":{"_uuid":"62826774bf054fb50a4da493826c153e87364ccd","_cell_guid":"ed42d9cc-8da2-4517-baf1-7f42e5b84893"}},{"cell_type":"markdown","source":"Why not looking at those with a lot of delay?","metadata":{"_uuid":"bb5ad1b809caf163ef5c0be42f9919b43f78687a","_cell_guid":"514d7eca-f935-4f25-806e-cd525c7e7b16"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df[df.PAY_1 > 3][['BILL_AMT2', 'PAY_AMT1', 'BILL_AMT1', 'PAY_1']].sample(20)","metadata":{"_uuid":"0f8945b2e842c70e082b509f916a7f8f3c208cd2","_cell_guid":"0ad35d39-3e7d-4ac4-a8c4-cdf39945da04"}},{"cell_type":"markdown","source":"One may wonder if that feature is useful at all once that you know the amount of money the clients have to pay. The more time I spend on it, the less this feauture seems important, although it can have the role of \"category\" for BILL_AMT. We keep it, but I don't like having undocumented labels, I decide to fix it to what seems more logical to me. We will test its importance later on.\n","metadata":{"_uuid":"6ee1fe096bc3d7ed8c2e7d780d24e04a3dc6192e","_cell_guid":"bea09172-e2bf-474d-b527-9db47029562f"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"fil = (df.PAY_1 == -2) | (df.PAY_1 == -1) | (df.PAY_1 == 0)\ndf.loc[fil, 'PAY_1'] = 0\nfil = (df.PAY_2 == -2) | (df.PAY_2 == -1) | (df.PAY_2 == 0)\ndf.loc[fil, 'PAY_2'] = 0\nfil = (df.PAY_3 == -2) | (df.PAY_3 == -1) | (df.PAY_3 == 0)\ndf.loc[fil, 'PAY_3'] = 0\nfil = (df.PAY_4 == -2) | (df.PAY_4 == -1) | (df.PAY_4 == 0)\ndf.loc[fil, 'PAY_4'] = 0\nfil = (df.PAY_5 == -2) | (df.PAY_5 == -1) | (df.PAY_5 == 0)\ndf.loc[fil, 'PAY_5'] = 0\nfil = (df.PAY_6 == -2) | (df.PAY_6 == -1) | (df.PAY_6 == 0)\ndf.loc[fil, 'PAY_6'] = 0\ndf[['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].describe()","metadata":{"_uuid":"7c111a9e9c6c095a25733022323ad518274c9b00","_cell_guid":"8b9da7f0-a32f-4609-9984-3d19ddfe994e"}},{"cell_type":"markdown","source":"Second, the feature LIMIT_BAL is the amount of given credit, I am incline to interpret it as the credit limit, thus the maximal amount of credit the customer can have in a month. However, being the range from 10000 to 1000000 and excluding we are not dealing with a very careless bank, I would interpret it as a limit in the year. \n\nTo check that, we could see if anyone has a higher BILL_AMT than the LIMIT_BAL","metadata":{"_uuid":"343d5e41be1c7ac54edcec456562f94a287de4b1","_cell_guid":"3d920bc2-5d46-4455-af6f-b58b0d6568a1"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"fil = ((df.LIMIT_BAL < df.BILL_AMT1) | \n      (df.LIMIT_BAL < df.BILL_AMT2) |\n      (df.LIMIT_BAL < df.BILL_AMT3) |\n      (df.LIMIT_BAL < df.BILL_AMT4) |\n      (df.LIMIT_BAL < df.BILL_AMT5) |\n      (df.LIMIT_BAL < df.BILL_AMT6))\ndf[fil].def_pay.value_counts()","metadata":{"_uuid":"835739c68d853320399d6a6cbce8acfea10e871d","_cell_guid":"ea164fb6-106e-4905-ae1e-d089a33bdaef"}},{"cell_type":"markdown","source":"Nope, it can happen and it doesn't lead to default necessarily. This surprises me because the bank is then asking to some clients to pay more than the bank is allowing them to spend. \n\nI am clearly missing something.\n\nLet's have a look to the BILL_AMT and PAY_AMT together if they make more sense","metadata":{"_uuid":"43b4c8a33f3a566a671a2b8d78cf85a439aabab3","_cell_guid":"79780f98-dc0f-402e-84e7-ba5e75d55a65"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":" df[['PAY_AMT6', 'BILL_AMT6', 'PAY_AMT5', \n     'BILL_AMT5', 'PAY_AMT4', 'BILL_AMT4', 'PAY_AMT3', 'BILL_AMT3', \n     'PAY_AMT2', 'BILL_AMT2',\n     'PAY_AMT1', 'BILL_AMT1',\n     'LIMIT_BAL', 'def_pay']].sample(30)","metadata":{"_uuid":"bbc44e12cbcd6b02abf639544b90cb0ce581a40e","_cell_guid":"a8f597c6-1cea-46e9-8fab-d25aa552b300"}},{"cell_type":"markdown","source":"To me it seems that it goes like that:\n* I have a BILL of X, I pay Y\n* The month after I have to pay X-Y + X', being X' my new expenses, I pay Y'\n* The month after I have to pay X+X' - Y - Y' + X'' , I pay Y''\n* So on so forth\n\nOn top of that I may or may not have months of delay.\n\nIt seems that if by september I have a bill too close to my limit, I generally fail.\n\nBut this is something you discuss about with your friends while making use of recreational drugs, we are here to be a little bit more scientific. Can I be more scientific than that?\n\n","metadata":{"_uuid":"fb856fce194700e5002283f9a2e70cf857b7a9c8","_cell_guid":"131435f6-e881-47c4-b08a-dbd995d55434"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"fil = ((df.PAY_AMT1 > df.BILL_AMT2) & df.PAY_1 > 0)\ndf[fil][['BILL_AMT1', 'PAY_1', 'LIMIT_BAL', 'def_pay']]","metadata":{"_uuid":"0d1382ee42f34665a5b4aaaa5faba7ccd83498bd","_cell_guid":"a14eb030-f6ea-4880-9f0f-05520340295b"}},{"cell_type":"markdown","source":"This throws me off. There are clients that paid more there were asked to, had even a negative bill in Sept., and still have a month of delay, and even defaulted the next month. ","metadata":{"_uuid":"0f262188bbd9a431710f2ad76987ede010467355","collapsed":true,"_cell_guid":"45721403-6e29-49eb-a745-ee51309c93f8"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"fil = ((df.PAY_AMT1 > df.BILL_AMT2))\nprint(\"Number of clients that tried to save themselves in the last month: \", len(df[fil]))\nprint(\"Percentage of default: \", df[fil].def_pay.mean())\nfil = ((df.PAY_AMT1 > df.BILL_AMT2) & df.PAY_1 > 0)\nprint(\"Percentage of default if delay: \", df[fil].def_pay.mean())\nprint(\"Value counts of delay: \", df[fil].PAY_1.value_counts())\nfil = ((df.PAY_AMT1 > df.BILL_AMT2) & df.PAY_1 < 1)\nprint(\"Percentage of default if no delay: \", df[fil].def_pay.mean())","metadata":{"_uuid":"205205f81e193303e3afbad88018308747aa9826","_cell_guid":"aba55826-4117-43b1-9e06-c62dbe094803"}},{"cell_type":"markdown","source":"That's weird, maybe the month of delay is assigned if one month the payment is 0. If this is the case my previous conclusion is wrong and the PAY_1 feature becomes more important (although the last result suggest that having 1 month of delay actually doesn't really matter for these clients). Let's try to verify this","metadata":{"_uuid":"1a0020047cb3e6cf02993e84407b2db3d050c789","_cell_guid":"9a0af0e6-77ea-4c56-934d-fd534edc9dd2"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"fil = ((df.PAY_6 == 0) & \n      ((df.PAY_5 > df.PAY_6) & (df.BILL_AMT6 > 0) & (df.PAY_AMT5 == 0))\n      )\n\ndf[fil][['PAY_6', 'BILL_AMT6', 'PAY_AMT5', 'PAY_5', 'BILL_AMT5', 'PAY_AMT4', 'PAY_4', 'PAY_AMT3']]","metadata":{"_uuid":"5b33a0442fe16046e0837e079a665ff8f7ba2e88","_cell_guid":"2acaf943-a9a5-423b-8ef8-9b5210cc513f"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"fil = ((df.PAY_5 == 0) & (df.PAY_6 == 0) &\n      ((df.PAY_4 > df.PAY_5) & (df.BILL_AMT5 > 0) & (df.PAY_AMT4 == 0))\n      )\n\ndf[fil][['BILL_AMT6', 'PAY_AMT5', 'PAY_5', 'BILL_AMT5', 'PAY_AMT4', 'PAY_4', 'BILL_AMT4', 'PAY_AMT3']]","metadata":{"_uuid":"8e877f2dd97a4e114a57e14f9604053b09b847a3","_cell_guid":"664cde57-d17c-4701-9af7-13f14fb44ba5"}},{"cell_type":"markdown","source":"Ok, I am incline to ignore the PAY_n features since I can't give sense to them. However, before looking at how important can be to understand your data before doing predictions, I would like to see what we get by simply feeding the machine with everything we have.\n\n# Blind machine learning\n\nI define it blind because I will just throw everything I have in them and nothing more than that. My hope is to see significant improvements once that I will engineer some features\n","metadata":{"_uuid":"220ef909218875387ff073a2d95b10a2eae77552","collapsed":true,"_cell_guid":"2d2bf3a0-d962-498f-bd08-815c68ab6090"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"","metadata":{"collapsed":true}}],"metadata":{"language_info":{"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}}}
